{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22356d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e31d9e8",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d9a8ce",
   "metadata": {},
   "source": [
    "__LightGBM__ is a gradient boosting framework that uses tree based learning algorithms. It is designed and efficient with the following advantages:\n",
    "\n",
    "\n",
    "- faster training speed and higher efficiency;\n",
    "\n",
    "\n",
    "- lower memory usage;\n",
    "\n",
    "\n",
    "- better accuracy;\n",
    "\n",
    "\n",
    "- support of parallel and GPU learning;\n",
    "\n",
    "\n",
    "- capable of handling large-scale data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fea443",
   "metadata": {},
   "source": [
    "## LightGBM intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e33be9d",
   "metadata": {},
   "source": [
    "__LightGBM__ grows tree vertically while other tree based learning algorithms grow trees horizontally. \n",
    "\n",
    "\n",
    "- It means that LightGBM grows tree leaf-wise while other algorithms grow level-wise. It will choose the leaf with the max delta loss to grow. When growing the same leaf, leaf-wise algorithm can reduce more loss than a level-wise algorithm.\n",
    "\n",
    "\n",
    "- so, we need to understand the distinction between leaf-wise tree growth and level-wise tree growth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d319888",
   "metadata": {},
   "source": [
    "### Important points about tree-growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff283023",
   "metadata": {},
   "source": [
    "- If we grow the full tree, __best-first (leaf-wise)__ and __depth-first (level_wise)__ will result in the same tree. The difference is in the order in which the tree is expanded. Since we don't normally grow trees to their full depth, order matters. \n",
    "\n",
    "\n",
    "- Application of early stopping criteria and pruning methods can result in very different trees. Because leaf-wise chooses splits based on their contribution to the global loss and not just the loss along a particular branch, it often (not always) will learn lower-error trees 'faster' than level-wise.\n",
    "\n",
    "\n",
    "- For a small number of nodes, leaf-wise will probably out-perform level-wise. As we add more nodes, without stopping or pruning they will converge to the same performance because they will literally build the same tree eventually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f47b1db",
   "metadata": {},
   "source": [
    "## LightGBM Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2d68cc",
   "metadata": {},
   "source": [
    "### Control Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef625e3c",
   "metadata": {},
   "source": [
    "- __max_depth__: it describes the maximum tree depth. This parameter is used to handle overfitting. If the model is overfitted, you should lower max_depth.\n",
    "\n",
    "\n",
    "- __min_data_in_leaf__: it's the minimum number of records a leaf may have. The default value is 20, optimal value. It's also used to deal with overfitting.\n",
    "\n",
    "\n",
    "- __feature_fraction__: used when your boosting is random forest. 0.8 feature fraction means LightGBM will select 80% of parameters randomly in each iteration for building trees.\n",
    "\n",
    "\n",
    "- __bagging_fraction__: specifies the fraction of data to be used for each iteration and is generally used to speed up the training and avoid overfitting. \n",
    "\n",
    "\n",
    "- __early_stopping_round__: this parameter can help you speed up your analysis. Model will stop training if one metric of one validation data doesn't improve in last early_stopping_round rounds. This will reduce excessive iterations.\n",
    "\n",
    "\n",
    "- __lambda__: lambda specifies regularization. Typical value ranges from 0 to 1.\n",
    "\n",
    "\n",
    "- __min_gain_to_split__: This parameter will describe the minimum gain to make a split. It can be used to control the number of useful splits in the tree.\n",
    "\n",
    "\n",
    "- __max_cat_group__: when the number of categories is big, finding the split point on it is easily over-fitting. So LightGBM merges them into 'max_cat_group' groups, and finds the split points on the group boundaries, default:64."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39e648f",
   "metadata": {},
   "source": [
    "### Core Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc76ca",
   "metadata": {},
   "source": [
    "- __Task__: it specifies the task you want to perform on data. It may be either train or predict.\n",
    "\n",
    "\n",
    "- __application__: specifies the application of your model, whether it is a regression problem or a classification problem. LightGBM will by default consider the model as a regression model.\n",
    "    \n",
    "    - regression;\n",
    "    - classification: binary classification;\n",
    "    - multiclass: for multiclass classification\n",
    "    \n",
    "    \n",
    "- __boosting__: defines the type of algorithm you want to run, default=gdbt.\n",
    "\n",
    "    - __gbdt__: traditional Gradient Boosting Decision Tree;\n",
    "    - __rf__: random forest;    \n",
    "    - __dart__: Dropouts meet Multiple Additive Regression Trees;    \n",
    "    - __goss__: Gradient-based One-Side Sampling.\n",
    "    \n",
    "    \n",
    "- __num_boost_round__: Number of boosting iterations, typically 100+;\n",
    "\n",
    "\n",
    "- __learning_rate__: this determines the impact of each tree on the final outcome. GBM works by starting with an initial estimate which is updated using the output of each tree. The learning parameter controls the magnitudeof this change in the estimates. Typical values: 0.1, 0.001, 0.003...\n",
    "\n",
    "\n",
    "- __num_leaves__: number of leaves in the full tree, default:31;\n",
    "\n",
    "\n",
    "- __device__: default: cpu, can also pass gpu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd0d484",
   "metadata": {},
   "source": [
    "### Metric Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c0bf34",
   "metadata": {},
   "source": [
    "- it specifies the loss for model building. Below are a few general losses for regression and classification:\n",
    "\n",
    "    - __mae__: mean absolute error;\n",
    "    - __mse__: mean squared error;\n",
    "    - __binary_logloss__: loss for binary classification;\n",
    "    - __multi_logloss__: loss for multi classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4436770",
   "metadata": {},
   "source": [
    "### IO Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74528742",
   "metadata": {},
   "source": [
    "- __max_bin__: it denotes the maximum number of bin that feature value will bucket in.\n",
    "\n",
    "\n",
    "- __categorical_feature__: it denotes the index of categorical features. If categorical_features=0,1,2 then column 0, column 1 and column 2 are categorical variables.\n",
    "\n",
    "\n",
    "- __ignore_column__: same as categorical_features but instead of considering specific columns as categorical, it will completely ignore them.\n",
    "\n",
    "\n",
    "- __save_binary__: if you are really dealing with the memory size of your data file then specify this parameter as 'True'. Specifying this parameter true will save the dataset to binary file, this binary file will speed your data reading time for the next time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260e963",
   "metadata": {},
   "source": [
    "# LightGBM implementation in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eab9381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   diagnosis  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./raw_data/Breast_cancer_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cc985d",
   "metadata": {},
   "source": [
    "## data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b13f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   mean_radius      569 non-null    float64\n",
      " 1   mean_texture     569 non-null    float64\n",
      " 2   mean_perimeter   569 non-null    float64\n",
      " 3   mean_area        569 non-null    float64\n",
      " 4   mean_smoothness  569 non-null    float64\n",
      " 5   diagnosis        569 non-null    int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 26.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd81e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_radius        0\n",
       "mean_texture       0\n",
       "mean_perimeter     0\n",
       "mean_area          0\n",
       "mean_smoothness    0\n",
       "diagnosis          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea62c2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb5d7197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_radius  mean_texture  mean_perimeter    mean_area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean_smoothness   diagnosis  \n",
       "count       569.000000  569.000000  \n",
       "mean          0.096360    0.627417  \n",
       "std           0.014064    0.483918  \n",
       "min           0.052630    0.000000  \n",
       "25%           0.086370    0.000000  \n",
       "50%           0.095870    1.000000  \n",
       "75%           0.105300    1.000000  \n",
       "max           0.163400    1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f2bc3c",
   "metadata": {},
   "source": [
    "__Comments__:\n",
    "\n",
    "- there are 6 variables in the dataset: 'mean_radius', 'mean_texture', 'mean_perimeter', 'mean_area', 'mean_smoothness' and 'diagnosis'. 'diagnosis' will be our target, the other 5 might be our features.\n",
    "\n",
    "\n",
    "- all 5 features are numerical and are defined as type 'float' while the target is defined as 'int'.\n",
    "\n",
    "\n",
    "- there are no NaN values and no duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e48b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
